{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization with Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the full evaluation of delivery 3 for the course \"Enterprise Data Science\". The single steps are seperated into different parts. The dynamic dashboard implements a diagram to show the COVID cases for all countries from the data set as well as its filtered data and the doubling rate. As bonus, it also shows the percentage of fully vaccinated people.\n",
    "\n",
    "Different to the provided notebook, OurWorldInData is used as data source as it provides much more data, among other things the vaccinations. Following from that, many parts had to be adapted to the new data source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fetch New Data from OurWorldInData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"../src/data/get_data.py\"\n",
    "import pandas as pd\n",
    "\n",
    "def get_data():\n",
    "    \"\"\" Get current data from Our World in Data \"\"\"\n",
    "    url = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "    df_owid = pd.read_csv(url, sep=',')\n",
    "    df_owid.to_csv(\"../data/raw/covid_full_data.csv\", sep=\";\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"../src/data/process_owid_data.py\"\n",
    "import pandas as pd\n",
    "\n",
    "def process_owid_data():\n",
    "    \"\"\" Processes the data fetched ffrom Our World in Data by selecting the relevant columns \"\"\"\n",
    "    df_owid = pd.read_csv(\"../data/raw/covid_full_data.csv\", sep=\";\")\n",
    "    df_selection = df_owid[['date', 'location', 'total_cases', 'people_vaccinated_per_hundred']].sort_values('date',ascending=True).reset_index(drop=True).copy()\n",
    "    df_selection = df_selection.drop(df_selection[df_selection['location'] == 'Western Sahara'].index)     # Drop Western Sahara as it has too little data for the rolling window\n",
    "    df_selection.to_csv(\"../data/processed/data_owid_selection.csv\", sep=\";\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_owid_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter Data and calculate doubling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"../src/features/build_features.py\"\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "\n",
    "def savgol_filter(df_input,column='total_cases', window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function \n",
    "        it ensures that the data structure is kept'''\n",
    "    window=5, \n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "    \n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "    \n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           5, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[column+'_filtered']=result\n",
    "    return df_result\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "def rolling_reg(df_input,col='total_cases'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "                \n",
    "    return result\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='total_cases'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['location',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "\n",
    "    pd_filtered_result=df_output[['location',filter_on]].groupby(['location']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "\n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='total_cases'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['location',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Error in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['location']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_1':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_processed_data = pd.read_csv(\"../data/processed/data_owid_selection.csv\", sep=\";\")\n",
    "    df_processed_data = calc_filtered_data(df_processed_data)\n",
    "    df_processed_data = calc_doubling_rate(df_processed_data)\n",
    "    df_processed_data = calc_doubling_rate(df_processed_data,'total_cases_filtered')\n",
    "    df_processed_data.to_csv(\"../data/processed/data_doubling_filtered.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load \"../src/visualization/visualize.py\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import dash\n",
    "from dash import dcc as doc\n",
    "from dash.dependencies import Input, Output\n",
    "from dash import html\n",
    "import dash_daq as daq\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure()\n",
    "df_covid = pd.read_csv(\"../data/processed/data_doubling_filtered.csv\", sep=\";\")\n",
    "countries = df_covid['location'].unique()\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "    html.H1('Dynamic Covid-19 Dashboard'),\n",
    "    html.Label('This dynamic dashboard implements '),\n",
    "    html.Label('Select the countries to display:'),\n",
    "    doc.Dropdown(\n",
    "        id = 'country_drop_down',\n",
    "        options=[{'label': country, 'value': country} for country in countries],\n",
    "        value=['Germany'],        # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "     doc.Markdown('''\n",
    "        ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        '''),\n",
    "\n",
    "\n",
    "    doc.Dropdown(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'Timeline Total Cases', 'value': 'total_cases'},\n",
    "        {'label': 'Timeline Total Cases Filtered', 'value': 'total_cases_filtered'},\n",
    "        {'label': 'Timeline Doubling Rate', 'value': 'total_cases_DR'},\n",
    "        {'label': 'Timeline Doubling Rate Filtered', 'value': 'total_cases_filtered_DR'},\n",
    "        {'label': 'Percentage Of Fully Vaccinated People', 'value': 'people_vaccinated_per_hundred'},\n",
    "    ],\n",
    "    value='total_cases',\n",
    "    multi=False\n",
    "    ),\n",
    "    daq.BooleanSwitch(id='loglin_switch', on=False, label=\"Logarithmic scale\", labelPosition=\"top\"),\n",
    "    doc.Graph(figure=fig,id='main_window_slope')\n",
    "])\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'), Input('loglin_switch', 'on'), Input('doubling_time', 'value')])\n",
    "def update_figure(countries_to_show, switch_state, show_doubling):\n",
    "    traces = []\n",
    "    ylabels = {'total_cases':'Total Cases of Infected People', 'total_cases_filtered':'Total Cases of Infected People (Filtered)',\n",
    "                 'total_cases_DR': 'Doubling Rate of Infected People', 'total_cases_filtered_DR': 'Doubling Rate of Infected People (Filtered)',\n",
    "                 'people_vaccinated_per_hundred': 'Percentage of Fully Vaccinated People'}\n",
    "    for country in countries_to_show:\n",
    "        df_plot=df_covid[df_covid['location']==country]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['location','total_cases','total_cases_filtered','total_cases_DR','total_cases_filtered_DR','date', 'people_vaccinated_per_hundred']].groupby(['location','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['location','total_cases','total_cases_filtered','total_cases_DR','total_cases_filtered_DR','date', 'people_vaccinated_per_hundred']].groupby(['location','date']).agg(np.sum).reset_index()\n",
    "        \n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                             y=df_plot[show_doubling],\n",
    "                             name=country,\n",
    "                             opacity=0.9,\n",
    "                             line_width=2,\n",
    "                             marker_size=4,\n",
    "                             mode='markers+lines'\n",
    "                          )\n",
    "                     )\n",
    "        \n",
    "    return {\n",
    "        'data': traces,\n",
    "        'layout': dict(width=1280,\n",
    "                        height=720,\n",
    "                        title=\"Covid-19 Dashboard\",\n",
    "                      xaxis={'tickangle':-45,\n",
    "                            'nticks':20,\n",
    "                            'tickfont':dict(size=14,color='#7f7f7f'),\n",
    "                             'title':'Time',\n",
    "                            },\n",
    "                      yaxis={\n",
    "                          'type': ('log' if switch_state else 'linear'),\n",
    "                          'range':('[0.1,100]' if switch_state else '[0,100000000]'),\n",
    "                          'title': ylabels[show_doubling] + (', Logarithmic' if switch_state else ''),\n",
    "                      })\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
